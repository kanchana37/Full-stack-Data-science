{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d2d2b14",
   "metadata": {},
   "source": [
    "## MACHINE LEARNING ASSIGNMENT -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbba417",
   "metadata": {},
   "source": [
    "### Q1. What does one mean by the term machine learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a1c61",
   "metadata": {},
   "source": [
    "Ans 1.\n",
    "Machine learning is a subfield of artificial intelligence (AI) that involves the development of algorithms and statistical models that enable computers to learn from data without being explicitly programmed.\n",
    "\n",
    "In other words, machine learning allows computers to automatically improve their performance at a task by learning from examples, rather than being explicitly programmed to carry out that task. This is achieved by feeding the computer large amounts of data and letting it learn patterns and rules from that data.\n",
    "\n",
    "Machine learning has numerous applications in various industries, such as image and speech recognition, natural language processing, predictive analytics, and autonomous vehicles, among others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6db986",
   "metadata": {},
   "source": [
    "### Q2. Can you think of 4 distinct types of issues where it shines?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7c251",
   "metadata": {},
   "source": [
    "Ans 2. Here are four distinct types of issues where machine learning excels:\n",
    "\n",
    "1. Classification Problems: Machine learning algorithms can be used to classify objects or data points into different categories based on their characteristics. For example, image classification algorithms can be trained to identify objects or features in images, while text classification algorithms can be used to categorize text documents based on their content.\n",
    "\n",
    "2. Regression Problems: Machine learning can be used to predict numerical values based on a set of input variables. For example, regression algorithms can be used to predict the price of a house based on its location, size, and other features.\n",
    "\n",
    "3. Anomaly Detection: Machine learning algorithms can be used to identify anomalies or outliers in datasets. This can be particularly useful in fraud detection, where abnormal transactions or behaviors can be flagged for further investigation.\n",
    "\n",
    "4. Recommendation Systems: Machine learning algorithms can be used to provide personalized recommendations to users based on their preferences and behaviors. This is commonly used in e-commerce and entertainment applications, where product or content recommendations can be tailored to each user's individual tastes and preferences.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a5c3fb",
   "metadata": {},
   "source": [
    "### Q3. What is a labeled training set, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796fe4f0",
   "metadata": {},
   "source": [
    "Ans 3. A labeled training set is a dataset used in supervised machine learning that consists of input data and corresponding output labels. Each data point in the training set is associated with a known label or target value, which the machine learning algorithm uses to learn how to make predictions on new, unseen data.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "1. A labeled training set is created by manually assigning labels to each data point. For example, if the task is image classification, each image in the dataset would be labeled with a corresponding category or class.\n",
    "\n",
    "2. The machine learning algorithm is trained on the labeled training set, using statistical techniques to learn the underlying patterns and relationships between the input data and the corresponding labels.\n",
    "\n",
    "3. Once the algorithm has been trained, it can be used to make predictions on new, unseen data. The algorithm takes the input data, applies the learned patterns and relationships, and produces a predicted label or output value.\n",
    "\n",
    "4. The accuracy of the algorithm's predictions can be evaluated by comparing them to the true labels of the test data. If the algorithm is accurate, it can be deployed to make predictions on new, real-world data.\n",
    "\n",
    "Labeled training sets are essential for supervised machine learning, as they provide the ground truth against which the algorithm can learn and improve. Without labeled data, the algorithm would have no way of knowing whether its predictions are accurate or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf1a93",
   "metadata": {},
   "source": [
    "### Q4. What are the two most important tasks that are supervised?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a955c7",
   "metadata": {},
   "source": [
    "Ans 4. The two most important tasks that are supervised in machine learning are:\n",
    "\n",
    "1.Classification: Classification is the task of assigning input data to one of several predefined categories based on the characteristics or features of the data. The goal is to train a machine learning model to accurately predict the correct category label for new, unseen input data. Examples of classification problems include image classification, where the goal is to distinguish between different objects or features in an image, and sentiment analysis, where the goal is to classify text documents as positive or negative based on their content.\n",
    "\n",
    "2.Regression: Regression is the task of predicting a numerical value or continuous output based on the input features or characteristics of the data. The goal is to train a machine learning model to accurately predict the output value for new, unseen input data. Examples of regression problems include predicting house prices based on features such as location, size, and number of bedrooms, and predicting stock prices based on historical data and market trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ff3be",
   "metadata": {},
   "source": [
    "### Q5. Can you think of four examples of unsupervised tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225e8c9",
   "metadata": {},
   "source": [
    "Ans 5. The four examples of unsupervised learning tasks:\n",
    "\n",
    "1) Clustering: In this task, the algorithm groups similar data points together based on their similarity or proximity to each other. The algorithm does not have any prior knowledge of the classes or labels to which the data points belong.\n",
    "\n",
    "2) Anomaly detection: In this task, the algorithm identifies outliers or anomalies in the data that do not conform to the expected patterns. This task does not require any labeled data, as the algorithm learns to identify anomalies based on the distribution of the data.\n",
    "\n",
    "3) Dimensionality reduction: This task involves reducing the number of features or variables in the data while preserving as much of the original information as possible. This can be done using techniques like Principal Component Analysis (PCA) or t-SNE.\n",
    "\n",
    "4) Generative modeling: In this task, the algorithm learns to generate new data that is similar to the training data. This can be done using techniques like Variational Autoencoders (VAEs) or Generative Adversarial Networks (GANs). This task does not require any labeled data, as the algorithm learns to generate new data based on the distribution of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6fdbe5",
   "metadata": {},
   "source": [
    "### Q6. State the machine learning model that would be best to make a robot walk through various unfamiliar terrains?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3087e7",
   "metadata": {},
   "source": [
    "Ans 6. The best machine learning model to make a robot walk through various unfamiliar terrains would be a reinforcement learning model.\n",
    "\n",
    "Reinforcement learning is a type of machine learning where an agent learns to make decisions by interacting with an environment. The agent receives feedback in the form of rewards or penalties based on the actions it takes, and it uses this feedback to learn a policy that maximizes its expected long-term reward.\n",
    "\n",
    "In the case of a robot navigating through various unfamiliar terrains, the reinforcement learning algorithm would train the robot to make decisions about how to move its limbs based on feedback from sensors that measure things like terrain roughness, slope, and obstacle height. The robot would learn to maximize a reward signal, such as the distance traveled or the time taken to complete the task, by adjusting its actions based on the feedback it receives.\n",
    "\n",
    "Overall, reinforcement learning is a powerful tool for training robots to navigate complex environments, and it has been used successfully in a variety of real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf417f37",
   "metadata": {},
   "source": [
    "### Q7. Which algorithm will you use to divide your customers into different groups?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7a92d1",
   "metadata": {},
   "source": [
    "Ans 6. Clustering is an unsupervised learning technique that groups together similar data points based on their characteristics. In the case of customer segmentation, we could use clustering to group customers with similar behavior or preferences.\n",
    "\n",
    "One commonly used clustering algorithm is k-means clustering, which partitions the data into k clusters based on the distance between data points. The algorithm iteratively assigns data points to the nearest cluster center and updates the center based on the mean of the data points in the cluster.\n",
    "\n",
    "Other clustering algorithms that could be used for customer segmentation include hierarchical clustering, DBSCAN, and Gaussian mixture models. The choice of algorithm would depend on the characteristics of the data and the desired output of the segmentation analysis.\n",
    "\n",
    "Overall, clustering is a useful technique for dividing customers into different groups, and it can provide insights that can inform marketing strategies, product development, and other business decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd24f2a6",
   "metadata": {},
   "source": [
    "### Q8. Will you consider the problem of spam detection to be a supervised or unsupervised learning problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dabe0d",
   "metadata": {},
   "source": [
    "Ans 8. Spam detection is typically considered a supervised learning problem.\n",
    "\n",
    "In supervised learning, the algorithm learns to make predictions based on labeled training data, where the input data is labeled with the correct output or class. In the case of spam detection, the algorithm is trained on a dataset of emails labeled as spam or not spam, and it learns to predict whether new, unseen emails are spam or not spam based on the features of the email (e.g., the presence of certain keywords, the sender's email address, etc.).\n",
    "\n",
    "There are also some unsupervised techniques that can be used for spam detection, such as clustering or anomaly detection. However, these techniques may not be as effective as supervised learning because they do not have access to labeled data to guide the learning process.\n",
    "\n",
    "Overall, while there are some unsupervised techniques that can be used for spam detection, supervised learning is typically considered the most effective approach for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e4229",
   "metadata": {},
   "source": [
    "### Q9. What is the concept of an online learning system?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d387e0c",
   "metadata": {},
   "source": [
    "Ans 9. An online learning system is a type of machine learning system that can learn and adapt to new data as it becomes available in real-time or near-real-time. In an online learning system, the model is updated incrementally as new data arrives, instead of being trained on a static dataset. This means that the system can continuously learn and improve its predictions over time as it receives more data.\n",
    "\n",
    "Online learning systems are commonly used in applications such as fraud detection, recommendation systems, and predictive maintenance, where the data is generated in real-time or near-real-time. These systems are also used in situations where it is not practical to store all of the data and train the model offline, such as in large-scale streaming data environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeff0331",
   "metadata": {},
   "source": [
    "### Q10. What is out-of-core learning, and how does it differ from core learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b5219b",
   "metadata": {},
   "source": [
    "Ans 10. Out-of-core learning is a type of machine learning that is designed to work with data that is too large to fit into the memory of a single machine. The data is typically stored on disk or in a distributed file system, and the learning algorithm operates on small batches of the data at a time.\n",
    "\n",
    "In contrast, core learning (also known as in-core learning) assumes that the entire dataset fits into the memory of a single machine, and the algorithm can operate on the full dataset at once.\n",
    "\n",
    "The key difference between out-of-core learning and core learning is how the data is processed. In out-of-core learning, the algorithm processes small batches of the data sequentially, typically using techniques like stochastic gradient descent (SGD) or mini-batch gradient descent. This allows the algorithm to operate on very large datasets without requiring a large amount of memory.\n",
    "\n",
    "In core learning, the entire dataset is loaded into memory at once, and the algorithm can operate on the full dataset using techniques like batch gradient descent. This can be faster than out-of-core learning for smaller datasets, as all of the data is available at once and there is no need to read from disk or a distributed file system.\n",
    "\n",
    "Overall, out-of-core learning is useful when working with very large datasets that cannot fit into memory, while core learning is suitable for smaller datasets that can be loaded into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e8d17",
   "metadata": {},
   "source": [
    "### Q11. What kind of learning algorithm makes predictions using a similarity measure?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4099b4e4",
   "metadata": {},
   "source": [
    "Ans 11. A type of learning algorithm that makes predictions using a similarity measure is called a \"nearest neighbor\" algorithm.\n",
    "\n",
    "Nearest neighbor algorithms are used in supervised learning to predict the class or value of a new data point by finding the closest data points in the training dataset. The distance metric used to measure similarity between the data points can vary, but common choices include Euclidean distance, Manhattan distance, and cosine similarity.\n",
    "\n",
    "The basic idea behind nearest neighbor algorithms is that data points that are close to each other in the feature space are likely to belong to the same class or have similar values. By finding the closest data points in the training dataset, the algorithm can predict the class or value of a new data point based on the labels of the nearby data points.They are widely used in applications such as image recognition, text classification, and recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d8c73",
   "metadata": {},
   "source": [
    "### Q12. What's the difference between a model parameter and a hyperparameter in a learning algorithm?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceffab5",
   "metadata": {},
   "source": [
    "Ans 12.In a machine learning algorithm, model parameters and hyperparameters are two different types of variables that play important roles in determining the performance of the model.\n",
    "\n",
    "Model parameters are variables that are learned by the algorithm during training. They are the weights or coefficients that are adjusted by the learning algorithm to fit the training data and minimize the error between the predicted output and the actual output. In other words, model parameters determine the functional form of the model and its ability to capture the patterns in the data.\n",
    "\n",
    "For example, in a linear regression model, the model parameters are the coefficients that determine the slope and intercept of the regression line. In a neural network model, the model parameters are the weights assigned to the connections between the neurons.\n",
    "\n",
    "On the other hand, hyperparameters are variables that are set by the user before the learning algorithm is run. They control the behavior of the algorithm and can influence the performance of the model. Hyperparameters are not learned by the algorithm during training, but they are tuned by the user to optimize the performance of the model.\n",
    "\n",
    "Examples of hyperparameters include the learning rate of the algorithm, the number of hidden layers in a neural network, the regularization parameter, and the kernel function in a support vector machine.The optimal values of hyperparameters are usually determined through trial and error or through more advanced techniques such as grid search or Bayesian optimization.\n",
    "\n",
    "Overall, model parameters are learned by the algorithm during training, while hyperparameters are set by the user before training and control the behavior of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c1e0a9",
   "metadata": {},
   "source": [
    "### Q13. What are the criteria that model-based learning algorithms look for? What is the most popular method they use to achieve success? What method do they use to make predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c98613",
   "metadata": {},
   "source": [
    "Ans 13. Model-based learning algorithms aim to create a model that captures the underlying structure of the data and can make accurate predictions on new, unseen data. To achieve this goal, they typically look for models that satisfy the following criteria:\n",
    "\n",
    "1.Goodness of fit: The model should fit the training data well, i.e., it should minimize the error between the predicted output and the actual output on the training data.\n",
    "\n",
    "2.Complexity: The model should be simple and interpretable, to avoid overfitting the training data and to enable insights into the underlying data patterns.\n",
    "\n",
    "3.Generalizability: The model should be able to make accurate predictions on new, unseen data, i.e., it should avoid overfitting the training data and capture the underlying data patterns.\n",
    "\n",
    "The most popular method used by model-based learning algorithms to achieve success is to use statistical inference techniques to estimate the parameters of the model. These techniques involve finding the model parameters that maximize the likelihood of the training data, subject to constraints such as simplicity or regularization.\n",
    "\n",
    "Once the model has been trained and the parameters have been estimated, model-based learning algorithms use the model to make predictions on new, unseen data. The specific method used to make predictions depends on the type of model being used. For example, linear regression models make predictions based on a linear combination of the input features, while decision trees make predictions based on a series of if-then rules. In general, the model-based learning algorithm applies the learned model to the new input data to generate the predicted output.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411435e4",
   "metadata": {},
   "source": [
    "### Q14. Can you name four of the most important Machine Learning challenges?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d568e96e",
   "metadata": {},
   "source": [
    "Ans 14. Four main challenges in Machine Learning include:\n",
    "1. Data quality and quantity: One of the biggest challenges in machine learning is having high-quality and sufficient data to train the models. This includes data that is accurate, complete, and representative of the problem space. Data quality can be affected by issues such as missing data, noise, and bias, while data quantity can be limited by factors such as cost, availability, and privacy concerns.\n",
    "\n",
    "2. Overfitting and underfitting: Another challenge in machine learning is finding the right balance between model complexity and generalization performance. Models that are too complex can overfit the training data and fail to generalize to new data, while models that are too simple can underfit the data and have high bias.\n",
    "\n",
    "3. Algorithm selection and tuning: Choosing the right algorithm for a particular problem and tuning its hyperparameters is another challenge in machine learning. Different algorithms have different strengths and weaknesses, and hyperparameters can significantly affect the performance of the model. Finding the right combination of algorithm and hyperparameters can require extensive experimentation and computational resources.\n",
    "\n",
    "4. Interpreting and explaining model results: Finally, interpreting and explaining the results of machine learning models can be a challenge, particularly in fields where decision-making is critical, such as healthcare and finance. Understanding how the model arrived at its predictions, identifying any biases or limitations, and communicating the results to stakeholders in a clear and understandable way are all important considerations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d22da",
   "metadata": {},
   "source": [
    "### Q15. What happens if the model performs well on the training data but fails to generalize the results to new situations? Can you think of three different options?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b860ce0",
   "metadata": {},
   "source": [
    "Ans 15. If a model performs well on the training data but fails to generalize to new situations, it is said to be overfitting the data. This can happen when the model is too complex and fits the noise in the training data, rather than the underlying patterns in the data.\n",
    "\n",
    "Here are three different options to address overfitting:\n",
    "\n",
    "1. Reduce the complexity of the model: One way to address overfitting is to reduce the complexity of the model by simplifying the architecture or reducing the number of features used in the model. This can help the model focus on the most important patterns in the data, rather than fitting to noise.\n",
    "\n",
    "2. Regularize the model: Another way to address overfitting is to add regularization to the model. Regularization adds a penalty term to the cost function that encourages the model to have smaller weights or coefficients. This helps to prevent the model from overemphasizing certain features or patterns in the data.\n",
    "\n",
    "3. Use more data: Finally, one way to address overfitting is to use more data to train the model. More data can help the model better capture the underlying patterns in the data and reduce the chance of overfitting. This can be particularly effective if the model is already fairly simple and regularized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e082f1e6",
   "metadata": {},
   "source": [
    "### Q16. What exactly is a test set, and why would you need one?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdab0fe",
   "metadata": {},
   "source": [
    "Ans 16. A test set is a separate set of data that is used to evaluate the performance of a machine learning model after it has been trained on a training set. The test set is typically used to estimate the generalization error or performance of the model on new, unseen data.\n",
    "\n",
    "The need for a test set arises from the fact that a machine learning model can overfit the training data, meaning that it may have high accuracy on the training data but perform poorly on new, unseen data. The purpose of the test set is to provide an unbiased evaluation of the model's performance on new data, which is a better indicator of how the model will perform in real-world scenarios.\n",
    "\n",
    "To use a test set, a portion of the data is set aside during the training phase and not used to train the model. Instead, this data is reserved for evaluating the model's performance after training. The model is trained on the remaining data, which is the training set. After training, the model is evaluated on the test set to estimate its performance on new, unseen data.\n",
    "\n",
    "It's important to ensure that the test set is representative of the problem space and is independent of the training set to ensure an unbiased evaluation. If the model is evaluated on the same data it was trained on, it can give a misleadingly optimistic view of its performance. Therefore, a separate test set is required to evaluate the model's performance on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e16a7",
   "metadata": {},
   "source": [
    "### Q17. What is a validation set's purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272237f8",
   "metadata": {},
   "source": [
    "Ans 17. The purpose of a validation set in machine learning is to assess the performance of a trained model on a new, unseen dataset. It is typically used to evaluate different models and/or hyperparameters during the development and tuning phase of a machine learning project.\n",
    "\n",
    "The validation set is created by setting aside a portion of the training data, separate from the data used for actual training. Once the model is trained on the remaining training data, it is evaluated on the validation set to determine how well it generalizes to new, unseen data. This helps to identify any issues with overfitting or underfitting the training data, and guides decisions about adjustments to the model or hyperparameters.\n",
    "\n",
    "The validation set is also useful for selecting the best model or hyperparameters from among several candidate models, by comparing their performance on the validation set. Once the best model is selected, it can be evaluated on a separate test set to get a final estimate of its performance on completely new data.\n",
    "\n",
    "In summary, the validation set serves as a way to evaluate a model's generalization performance on new, unseen data and to guide decisions about model selection and tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3441873f",
   "metadata": {},
   "source": [
    "### Q18. What precisely is the train-dev kit, when will you need it, how do you put it to use?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d23765",
   "metadata": {},
   "source": [
    "The train-dev kit, also known as the development set or validation set, is a dataset used for model development and tuning. It is separate from both the training set and the test set and is used to evaluate the model's performance during the development process.\n",
    "\n",
    "The main purpose of the train-dev kit is to prevent overfitting to the test set. When tuning a model, it is common to try out many different hyperparameters and model architectures. If the model is evaluated on the test set after each change, there is a risk of overfitting to the test set, as the model can inadvertently learn from the test set. This can result in an overly optimistic estimate of the model's performance on new data.\n",
    "\n",
    "To avoid overfitting to the test set, the train-dev kit is used to evaluate the model during development. The training set is used to train the model, and the train-dev kit is used to evaluate the model's performance on new data that it has not seen during training. By evaluating the model on the train-dev kit, we can get a more accurate estimate of its performance on new data and avoid overfitting to the test set.\n",
    "\n",
    "To use the train-dev kit, the dataset is typically split into three parts: the training set, the train-dev kit, and the test set. The model is trained on the training set, and the hyperparameters are tuned using the train-dev kit. Once the hyperparameters have been chosen, the final model is trained on the combined training set and train-dev kit, and its performance is evaluated on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff9b00",
   "metadata": {},
   "source": [
    "### Q19. What could go wrong if you use the test set to tune hyperparameters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cf6223",
   "metadata": {},
   "source": [
    "Ans 19.If you use the test set to tune hyperparameters, there is a risk of overfitting to the test set, which can lead to overly optimistic estimates of the model's performance on new, unseen data.\n",
    "\n",
    "Here's how it can happen:\n",
    "\n",
    "Suppose you use the test set to evaluate the performance of different models or hyperparameters, and then choose the best-performing one. If you use the same test set to evaluate the final model, it is possible that the model has overfit to the test set, i.e., the model may have learned to perform well on the specific examples in the test set rather than generalizing well to new, unseen data.\n",
    "\n",
    "As a result, when you deploy the model in the real world, it may perform poorly because it hasn't learned to generalize to new data outside of the test set. This is often referred to as \"data leakage\" or \"testing contamination\".\n",
    "\n",
    "To avoid this, it is important to keep the test set completely separate from the training and validation sets during model development and hyperparameter tuning. Instead, use the validation set to tune hyperparameters and evaluate different models, and reserve the test set for the final evaluation of the selected model after all hyperparameter tuning is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c75e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
